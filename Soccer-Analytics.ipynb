{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold, RepeatedKFold, RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import warnings\n",
    "\n",
    "\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data, merget tables, and create new variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(\"database.sqlite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data from each table\n",
    "\n",
    "league = pd.read_sql(\"select * from league;\", conn)\n",
    "\n",
    "country = pd.read_sql(\"select * from country;\", conn)\n",
    "\n",
    "team = pd.read_sql(\"select * from team;\", conn)\n",
    "\n",
    "match = pd.read_sql(\"select * from match;\", conn)\n",
    "\n",
    "player = pd.read_sql(\"select * from player;\", conn)\n",
    "\n",
    "plyr_attr = pd.read_sql(\"select * from player_attributes;\", conn)\n",
    "\n",
    "team_attr = pd.read_sql(\"select * from team_attributes;\", conn) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join league and country tables\n",
    "\n",
    "league.rename(columns = {\"name\": \"league_name\"}, inplace = True)\n",
    "league = league.merge(country,how=\"inner\",on=\"id\")\n",
    "league.drop(['id'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select useful columns from match table\n",
    "\n",
    "match = match[[\"id\",\"league_id\",\"season\",\"stage\",\"date\",\"match_api_id\",\"home_team_api_id\",\"away_team_api_id\",\n",
    "                 \"home_team_goal\",\"away_team_goal\",\"B365H\", \"B365D\",\"B365A\"]]\n",
    "\n",
    "# Join matches and team name data\n",
    "\n",
    "match = match.merge(team[[\"team_api_id\",\"team_long_name\"]], how=\"left\", left_on = \"home_team_api_id\", right_on = \"team_api_id\")\n",
    "match.rename(columns = {\"team_long_name\": \"home_team_name\"}, inplace = True)\n",
    "match.drop([\"team_api_id\"], axis = 1, inplace = True)\n",
    "\n",
    "match = match.merge(team[[\"team_api_id\",\"team_long_name\"]], how=\"left\", left_on = \"away_team_api_id\", right_on = \"team_api_id\")\n",
    "match.rename(columns = {\"team_long_name\": \"away_team_name\"}, inplace = True)\n",
    "match.drop([\"team_api_id\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join matches and league/country data\n",
    "\n",
    "match = match.merge(league, how=\"left\", left_on = \"league_id\", right_on = \"country_id\")\n",
    "match.drop([\"country_id\"],axis = 1, inplace = True)\n",
    "match.rename(columns = {\"name\": \"country\"}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tag each match as a home win, draw, or away win\n",
    "\n",
    "match[\"home_win\"] = np.where(match[\"home_team_goal\"] > match[\"away_team_goal\"], 1, 0)\n",
    "match[\"draw\"] = np.where(match[\"home_team_goal\"] == match[\"away_team_goal\"], 1, 0)\n",
    "match[\"away_win\"] = np.where(match[\"home_team_goal\"] < match[\"away_team_goal\"], 1, 0)\n",
    "\n",
    "match[\"home_result\"] = np.where(match[\"home_team_goal\"] > match[\"away_team_goal\"], \"W\", \n",
    "                                     (np.where(match[\"home_team_goal\"] < match[\"away_team_goal\"], \"L\", \"D\")))\n",
    "\n",
    "# Filter matches to only include England, Spain, and Italy\n",
    "# Over this time period, these three leagues were the best in the world and also each have 20 teams in them\n",
    "# This makes for comparisons that make more sense\n",
    "match = match[match[\"country\"].isin([\"England\",\"Spain\",\"Italy\"])]\n",
    "\n",
    "# Convert B365 betting odds to probabilities\n",
    "\n",
    "match[\"p_home_win\"] = 1 / match[\"B365H\"]\n",
    "match[\"p_draw\"] = 1 / match[\"B365D\"]\n",
    "match[\"p_away_win\"] = 1 / match[\"B365A\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get unique combinations of teams, seasons, stages, and countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique combinations of the teams, seasons, stages, and countries before calling get_previous_matches\n",
    "\n",
    "def create_home_team_pkeys():\n",
    "    \"\"\"\n",
    "    A function to concatenate home team data into a key\n",
    "    \"\"\"\n",
    "    \n",
    "    team_by_season = match[[\"home_team_name\",\"home_team_api_id\",\"stage\",\"season\",\"country\"]]\n",
    "    team_by_season[\"pkey\"] = team_by_season.home_team_name.str.cat(team_by_season.home_team_api_id.astype(str), sep='-')\n",
    "    \n",
    "    return team_by_season\n",
    "    \n",
    "    \n",
    "def create_away_team_pkeys():\n",
    "    \"\"\"\n",
    "    A function to concatenate away team data into a key\n",
    "    \"\"\"\n",
    "    \n",
    "    team_by_season = match[[\"away_team_name\",\"away_team_api_id\",\"stage\",\"season\",\"country\"]]\n",
    "    team_by_season[\"pkey\"] = team_by_season.away_team_name.str.cat(team_by_season.away_team_api_id.astype(str), sep='-')\n",
    "    \n",
    "    return team_by_season\n",
    "    \n",
    "\n",
    "def concat_stage_season_country(team_by_season):\n",
    "    \"\"\"\n",
    "    A function to combine the home and away keys with stage, season, country\n",
    "    \"\"\"\n",
    "    \n",
    "    team_by_season[\"pkey\"] = team_by_season.pkey.str.cat(team_by_season.stage.astype(str), sep = \"-\")\n",
    "    team_by_season[\"pkey\"] = team_by_season.pkey.str.cat(team_by_season.season.astype(str), sep = \"-\")\n",
    "    team_by_season[\"pkey\"] = team_by_season.pkey.str.cat(team_by_season.country.astype(str), sep = \"-\")\n",
    "    list_teams_season = list(team_by_season[\"pkey\"].unique())\n",
    "    \n",
    "    return list_teams_season\n",
    "\n",
    "\n",
    "def create_team_tuples(list_teams_season):\n",
    "    \"\"\"\n",
    "    A function to split the combination of team-stage-season-country into parts\n",
    "    Insert them into a tuple\n",
    "    Then insert them into a list\n",
    "    \"\"\"\n",
    "    \n",
    "    team_tups = []\n",
    "\n",
    "    for i in range(len(list_teams_season)):\n",
    "        split = list_teams_season[i].split(\"-\", 5)\n",
    "        team_tups.append((split[0], split[1], split[2], split[3], split[4]))\n",
    "        \n",
    "    return team_tups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the functions above to create tuples of the home and away teams\n",
    "# These tuples will then be submitted as arguments to get_previous_matches\n",
    "\n",
    "home_pkeys = create_home_team_pkeys()\n",
    "home_team_list = concat_stage_season_country(home_pkeys)\n",
    "home_tuples = create_team_tuples(home_team_list)\n",
    "\n",
    "away_pkeys = create_away_team_pkeys()\n",
    "away_team_list = concat_stage_season_country(away_pkeys)\n",
    "away_tuples = create_team_tuples(away_team_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to assist getting previous matches for each game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_previous_matches(team_name, team_id, stage, season, country):\n",
    "    \"\"\"\n",
    "    Helper function to get the 10 previous matches played by a team at a given stage of the season\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get all matches played by a team in a season\n",
    "    match_team = match[((match[\"home_team_name\"] == team_name) | (match[\"away_team_name\"] == team_name)) &\n",
    "                        (match[\"season\"] == season)]\n",
    "    \n",
    "    # Get the last 10 matches played \n",
    "    # This will allow the team's previous run of form to be considered\n",
    "    match_prev = match_team[match_team[\"stage\"] < stage].sort_values(by = \"stage\", ascending = False).iloc[0:10,:]\n",
    "    \n",
    "    return match_prev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ppg_in_prev_matches(team_name, team_id, stage, season, country):\n",
    "    \"\"\"\n",
    "    A function to get the average points earned per game (not goals) by a team in its previous 10 matches\n",
    "    \"\"\"\n",
    "    \n",
    "    match_prev = get_previous_matches(team_name, team_id, stage, season, country)\n",
    "    \n",
    "    points_last_10 = 0\n",
    "    \n",
    "    for index, row in match_prev.iterrows():\n",
    "        if row[\"home_win\"] == 1 and row[\"home_team_name\"] == team_name:\n",
    "            points_last_10 += 3\n",
    "        elif row[\"away_win\"] == 1 and row[\"away_team_name\"] == team_name:\n",
    "            points_last_10 += 3\n",
    "        elif row[\"draw\"] == 1:\n",
    "            points_last_10 += 1\n",
    "            \n",
    "    ppg = points_last_10/10\n",
    "            \n",
    "    return ppg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_goals_in_prev_matches(team_name, team_id, stage, season, country):\n",
    "    \"\"\"\n",
    "    A function to get the average home/away goals for/against by a team in its previous 10 matches\n",
    "    Returns data as a dictionary\n",
    "    \"\"\"\n",
    "    \n",
    "    match_prev = get_previous_matches(team_name, team_id, stage, season, country)\n",
    "    \n",
    "    # Get the average home and away goals scored in the last 10 matches\n",
    "    home_goals_for = match_prev.home_team_goal[match_prev.home_team_name == team_name].mean()\n",
    "    away_goals_for = match_prev.away_team_goal[match_prev.away_team_name == team_name].mean()\n",
    "\n",
    "    # Get the home and away goals conceded in the last 10 matches\n",
    "    home_goals_against = match_prev.away_team_goal[match_prev.home_team_name == team_name].mean()\n",
    "    away_goals_against = match_prev.home_team_goal[match_prev.away_team_name == team_name].mean()\n",
    "    \n",
    "    return {\"HGF\": home_goals_for, \"AGF\": away_goals_for, \"HGA\": home_goals_against, \"AGA\": away_goals_against}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_team_form_data(team_name, team_id, stage, season, country):\n",
    "    \"\"\"\n",
    "    Function to get the data referenced in get_goals_in_prev_matches and get_ppg_in_prev_matches\n",
    "    Returns a dictionary, which will then be put into a list and cast as a dataframe\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get data on previous goals\n",
    "    goal_data = get_goals_in_prev_matches(team_name, team_id, stage, season, country)\n",
    "    \n",
    "    home_goals_for = goal_data[\"HGF\"]\n",
    "    home_goals_against = goal_data[\"AGF\"]\n",
    "    away_goals_for = goal_data[\"HGA\"]\n",
    "    away_goals_against = goal_data[\"AGA\"]\n",
    "\n",
    "    # Get the number of points per game earned in the last 10 games (3 for win, 1 for draw)\n",
    "    prev_points = get_ppg_in_prev_matches(team_name, team_id, stage, season, country)\n",
    "\n",
    "    # Return data\n",
    "    return {\"team\": team_name, \"tid\": team_id, \"country\": country,\n",
    "            \"stage\": stage, \"season\": season, \"PPG\": prev_points, \n",
    "            \"HGF\": home_goals_for, \"HGA\": home_goals_against, \n",
    "            \"AGF\": away_goals_for, \"AGA\": away_goals_against}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_run_of_form_data(team_tups):\n",
    "    \"\"\"\n",
    "    A function to pull run-of-form data for each team/season/stage combination in the dataset\n",
    "    \"\"\"\n",
    "    run_of_form = []\n",
    "    \n",
    "    for t in team_tups:\n",
    "        team_name = t[0]\n",
    "        team_id = int(t[1])\n",
    "        stage = int(t[2])\n",
    "        season = t[3]\n",
    "        country = t[4]\n",
    "        d = get_team_form_data(team_name, team_id, stage, season, country)\n",
    "        run_of_form.append(d)\n",
    "                    \n",
    "    return run_of_form"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create prediction input dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the run of form for each team that played in the dataset\n",
    "form_home = get_run_of_form_data(home_tuples)\n",
    "form_away = get_run_of_form_data(away_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the list of dictionaries into dataframes\n",
    "# Filter for only stages after 10, to have a large enough sample when predicting results\n",
    "# Drop the team name field to avoid duplicates when merging later\n",
    "\n",
    "form_home = pd.DataFrame(form_home)\n",
    "form_home = form_home[form_home[\"stage\"] > 10]\n",
    "form_home = form_home[[\"tid\",\"country\",\"stage\",\"season\",\"PPG\",\"HGF\",\"HGA\",\"AGF\",\"AGA\"]]\n",
    "\n",
    "form_away = pd.DataFrame(form_away)\n",
    "form_away = form_away[form_away[\"stage\"] > 10]\n",
    "form_away = form_away[[\"tid\",\"country\",\"stage\",\"season\",\"PPG\",\"HGF\",\"HGA\",\"AGF\",\"AGA\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the home dataframe with the full match dataset\n",
    "match_form = match.merge(form_home, how=\"left\", \n",
    "                     left_on = [\"home_team_api_id\",\"country\",\"stage\",\"season\"], \n",
    "                     right_on = [\"tid\",\"country\",\"stage\",\"season\"])\n",
    "\n",
    "# Drop tid as it is duplicated\n",
    "match_form.drop([\"tid\"], axis = 1, inplace = True)\n",
    "\n",
    "# Rename columns to refer to home form\n",
    "match_form.rename(columns = {\"PPG\": \"home_ppg\", \"HGF\": \"home_hgf\", \"HGA\":\"home_hga\",\n",
    "                        \"AGF\": \"home_agf\", \"AGA\": \"home_aga\"}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the away dataframe with the resulting full+form_home dataset\n",
    "match_form = match_form.merge(form_away, how=\"left\", \n",
    "                     left_on = [\"away_team_api_id\",\"country\",\"stage\",\"season\"], \n",
    "                     right_on = [\"tid\",\"country\",\"stage\",\"season\"])\n",
    "\n",
    "# Drop tid as it is duplicated\n",
    "match_form.drop([\"tid\"], axis = 1, inplace = True)\n",
    "\n",
    "# Rename columns to refer to home form\n",
    "match_form.rename(columns = {\"PPG\": \"away_ppg\", \"HGF\": \"away_hgf\", \"HGA\":\"away_hga\",\n",
    "                        \"AGF\": \"away_agf\", \"AGA\": \"away_aga\"}, inplace = True)\n",
    "\n",
    "# Filter to only include stage > 10\n",
    "# So that every match has the same amount of data predicting its result\n",
    "match_form = match_form[match_form[\"stage\"] > 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the final dataset for modeling\n",
    "# Drop the six rows that have NaN values in p_home_win, p_draw, p_away_win\n",
    "result_df = match_form[[\"home_ppg\", \"home_hgf\", \"home_hga\", \"home_agf\", \"home_aga\",\n",
    "                    \"away_ppg\", \"away_hgf\", \"away_hga\", \"away_agf\", \"away_aga\",\n",
    "                    \"p_home_win\",\"p_draw\",\"p_away_win\", \"home_result\"]].dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = result_df.iloc[:, 0:-1]\n",
    "y = result_df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression: One v Rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5398406374501992"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression with one v rest multiclass parameter\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "model = LogisticRegression(multi_class = \"ovr\")\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5415479776007852 0.012728816597034688\n"
     ]
    }
   ],
   "source": [
    "# KFold cross validation logistic regression\n",
    "\n",
    "model = LogisticRegression(multi_class = \"ovr\")\n",
    "kfold = RepeatedStratifiedKFold(n_splits = 10, n_repeats = 10, random_state = 0)\n",
    "log_reg_scores = cross_val_score(model, X, y, cv=kfold)\n",
    "\n",
    "print(log_reg_scores.mean(), log_reg_scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.21209508879201905, 'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning for one vs rest logistic regression\n",
    "\n",
    "params = {\"C\": np.logspace(start = -3, stop = 3, num=50, endpoint = True, base = 10),\n",
    "          \"penalty\": [\"l1\", \"l2\"]}\n",
    "\n",
    "log_reg_cv = GridSearchCV(LogisticRegression(multi_class = \"ovr\"), params, cv=5)\n",
    "log_reg_cv.fit(X_train, y_train)\n",
    "\n",
    "print(log_reg_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of best one v rest logistic regression:  0.5403386454183267\n"
     ]
    }
   ],
   "source": [
    "# Best estimator multinomial logistic regression\n",
    "\n",
    "log_reg_cv.best_estimator_.fit(X_train, y_train)\n",
    "y_pred = log_reg_cv.best_estimator_.predict(X_test)\n",
    "print(\"Accuracy score of best one v rest logistic regression: \", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression: Multinomial Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5493027888446215"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multinomial logistic regression\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "model = LogisticRegression(multi_class=\"multinomial\", solver=\"lbfgs\")\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5419215135086897 0.012471660772451343\n"
     ]
    }
   ],
   "source": [
    "# K Fold cross validation multinomial logistic regression\n",
    "\n",
    "model = LogisticRegression(multi_class=\"multinomial\", solver=\"lbfgs\")\n",
    "kfold = RepeatedStratifiedKFold(n_splits = 10, n_repeats = 10, random_state = 0)\n",
    "mlm_scores = cross_val_score(model, X, y, cv=kfold)\n",
    "\n",
    "print(mlm_scores.mean(), mlm_scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.15998587196060574, 'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning for multinomial logistic regression\n",
    "\n",
    "params = {\"C\": np.logspace(start = -3, stop = 3, num=50, endpoint = True, base = 10),\n",
    "          \"penalty\": [\"l1\", \"l2\"]}\n",
    "\n",
    "grid_log_reg = GridSearchCV(LogisticRegression(multi_class=\"multinomial\", solver=\"lbfgs\"), params, cv=5)\n",
    "grid_log_reg.fit(X_train, y_train)\n",
    "\n",
    "print(grid_log_reg.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of best multinomial logistic regression:  0.5502988047808764\n"
     ]
    }
   ],
   "source": [
    "# Best estimator multinomial logistic regression\n",
    "\n",
    "grid_log_reg.best_estimator_.fit(X_train, y_train)\n",
    "y_pred = grid_log_reg.best_estimator_.predict(X_test)\n",
    "print(\"Accuracy score of best multinomial logistic regression: \", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5293824701195219"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Support vector classifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "model = SVC(decision_function_shape = \"ovo\")\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5385286348526426 0.012005485253309809\n"
     ]
    }
   ],
   "source": [
    "# K fold cross validation of SVC\n",
    "\n",
    "svc = SVC(decision_function_shape = \"ovo\", kernel='linear', C=1, random_state=42)\n",
    "kfold = RepeatedStratifiedKFold(n_splits = 10, n_repeats = 10, random_state = 0)\n",
    "svc_scores = cross_val_score(svc, X, y, cv=kfold)\n",
    "\n",
    "print(svc_scores.mean(), svc_scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:   10.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1, 'gamma': 0.01, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning of support vector classifier\n",
    "\n",
    "params = {\"C\":[0.01, 0.1, 1],\n",
    "          \"gamma\":[0.01, 0.1, 1],\n",
    "          \"kernel\": [\"linear\"]\n",
    "         }\n",
    "\n",
    "grid_svc = GridSearchCV(SVC(), params, scoring = \"accuracy\", n_jobs = -1, verbose = 1, cv = 5)\n",
    "grid_svc.fit(X_train, y_train)\n",
    "\n",
    "print(grid_svc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of best support vector classifier:  0.5313745019920318\n"
     ]
    }
   ],
   "source": [
    "# Best estimator SVC\n",
    "\n",
    "grid_svc.best_estimator_.fit(X_train, y_train)\n",
    "y_pred = grid_svc.predict(X_test)\n",
    "print(\"Accuracy score of best support vector classifier: \", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.522410358565737"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest Classifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "model = RandomForestClassifier(random_state = 0)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5187861588916405 0.015023214202749692\n"
     ]
    }
   ],
   "source": [
    "# K fold cross validation Random Forest Classifier\n",
    "\n",
    "rfc = RandomForestClassifier(random_state=0)\n",
    "kfold = RepeatedStratifiedKFold(n_splits = 10, n_repeats = 10, random_state = 0)\n",
    "rfc_scores = cross_val_score(rfc, X, y, cv=kfold)\n",
    "\n",
    "print(rfc_scores.mean(), rfc_scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:   14.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_features': 'sqrt', 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning of the random forest classifier\n",
    "\n",
    "params = {\"n_estimators\": [100, 120, 150], \n",
    "          \"max_features\": [\"auto\",\"sqrt\",\"log2\"]\n",
    "         }\n",
    "\n",
    "grid_rfc = GridSearchCV(RandomForestClassifier(), param_grid = params, scoring = \"accuracy\", \n",
    "                        n_jobs = -1, verbose = 1, cv = 5)\n",
    "\n",
    "grid_rfc.fit(X_train, y_train)\n",
    "\n",
    "print(grid_rfc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of best random forest classifier:  0.524402390438247\n"
     ]
    }
   ],
   "source": [
    "# Best estimator random forest classifier\n",
    "\n",
    "grid_rfc.best_estimator_.fit(X_train, y_train)\n",
    "y_pred = grid_rfc.best_estimator_.predict(X_test)\n",
    "print(\"Accuracy score of best random forest classifier: \", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Neighbors Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43227091633466136"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# K Neighbors classifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "model = KNeighborsClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.42742533966936613 0.016652801384845817\n"
     ]
    }
   ],
   "source": [
    "# K fold cross validation K Neighbors classifier\n",
    "\n",
    "knc = KNeighborsClassifier()\n",
    "kfold = RepeatedStratifiedKFold(n_splits = 10, random_state=0)\n",
    "knc_scores = cross_val_score(knc, X, y, cv=kfold)\n",
    "\n",
    "print(knc_scores.mean(), knc_scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    2.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algorithm': 'auto', 'n_neighbors': 8, 'p': 2, 'weights': 'distance'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 240 out of 240 | elapsed:    8.2s finished\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning of the K Neighbors classifier\n",
    "\n",
    "params = {\"n_neighbors\": [3, 4, 5, 6, 7, 8], \n",
    "          \"weights\": [\"uniform\",\"distance\"],\n",
    "          \"algorithm\": [\"auto\", \"ball_tree\",\"kd_tree\", \"brute\"],\n",
    "          \"p\":[2]\n",
    "         }\n",
    "\n",
    "grid_knc = GridSearchCV(KNeighborsClassifier(), param_grid = params, scoring = \"accuracy\", \n",
    "                        n_jobs = -1, verbose = 1, cv = 5)\n",
    "\n",
    "grid_knc.fit(X_train, y_train)\n",
    "\n",
    "print(grid_knc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of best K Neighbors Classifier:  0.4716135458167331\n"
     ]
    }
   ],
   "source": [
    "# Best estimator K Neighbors classifier\n",
    "\n",
    "grid_knc.best_estimator_.fit(X_train, y_train)\n",
    "y_pred = grid_knc.best_estimator_.predict(X_test)\n",
    "print(\"Accuracy score of best K Neighbors Classifier: \", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
